{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import col, explode, udf, lit\n",
    "from pyspark.sql.types import IntegerType, FloatType, ArrayType, StringType\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Recommendation\") \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\",\"mongodb://localhost:27017/imdb.movies\")\\\n",
    "    .config(\"spark.mongodb.read.connection.uri\",\"mongodb://localhost:27017/imdb.movies\")\\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector:10.0.5\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "links = spark.read.csv(\"data/links.csv\",header=True)\n",
    "movies = spark.read.csv(\"data/movies.csv\",header=True)\n",
    "ratings = spark.read.csv(\"data/ratings.csv\",header=True)\n",
    "tags = spark.read.csv(\"data/tags.csv\",header=True)\n",
    "imdb = spark.read.option(\"multiline\",\"true\").json(\"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert movies_imdb to collection \n",
    "import json\n",
    "\n",
    "def lower_case(x):\n",
    "    res = []\n",
    "    for x_ in x:\n",
    "        res.append(x_.lower())\n",
    "    return res\n",
    "\n",
    "movies_links = movies.join(links, ['movieId'], 'left')\\\n",
    "    .withColumnRenamed('title', 'old_title')\\\n",
    "    .withColumnRenamed('genres', 'old_genres')\\\n",
    "    .drop('tmdbId')\n",
    "\n",
    "movies_imdb = movies_links.join(imdb, ['imdbId'], 'left').dropna(how=\"any\")\\\n",
    "    .select(\"imdbId\",\"movieId\",\"title\",\"year\",\"poster\", \"rating\", \"summary\", \"time\", \"genres\" )\n",
    "    \n",
    "to_lower_case = udf(lower_case, ArrayType(StringType()))\n",
    "\n",
    "movies_imdb_convert = movies_imdb.withColumn(\"imdbId\",movies_imdb.imdbId.cast(IntegerType())) \\\n",
    "    .withColumn('movieId', movies_imdb.movieId.cast(IntegerType())) \\\n",
    "    .withColumn('rating', movies_imdb.rating.cast(FloatType()))\\\n",
    "    .withColumn(\"genres\", to_lower_case(col(\"genres\")))\\\n",
    "    .select(\"imdbId\",\"movieId\",\"title\",\"year\",\"poster\", \"rating\", \"summary\", \"time\", \"genres\" )\n",
    "\n",
    "# movies_imdb_convert.write.format(\"mongodb\").mode(\"overwrite\").save()\n",
    "\n",
    "# movies_imdb_convert.toPandas().to_csv('movies_imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type, drop duplicate, selection column\n",
    "ratings = ratings.withColumn(\"userId\",ratings.userId.cast(IntegerType())) \\\n",
    "    .withColumn('movieId', ratings.movieId.cast(IntegerType())) \\\n",
    "    .withColumn('rating', ratings.rating.cast(FloatType()))\\\n",
    "    .drop('timestamp').dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  98.30% sparse.\n"
     ]
    }
   ],
   "source": [
    "# check sparsity data\n",
    "def get_sparsity(ratings):\n",
    "    # Count the total number of ratings in the dataset\n",
    "    count_nonzero = ratings.select(\"rating\").count()\n",
    "\n",
    "    # Count the number of distinct userIds and distinct movieIds\n",
    "    denominator = ratings.select(\"userId\").distinct().count() * ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "    # Divide the numerator by the denominator\n",
    "    sparsity = (1.0 - (count_nonzero *1.0)/denominator)*100\n",
    "    print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% sparse.\")\n",
    "    \n",
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by userId, count ratings\n",
    "userId_ratings = ratings.groupBy(\"userId\").count().orderBy('count', ascending=False)\n",
    "userId_ratings.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by userId, count ratings\n",
    "movieId_ratings = ratings.groupBy(\"movieId\").count().orderBy('count', ascending=False)\n",
    "movieId_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import als depedencies\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([.8, .2], seed=123)\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(\n",
    "         userCol=\"userId\", \n",
    "         itemCol=\"movieId\",\n",
    "         ratingCol=\"rating\", \n",
    "         nonnegative = True, \n",
    "         implicitPrefs = False,\n",
    "         coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "type(als)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "           metricName=\"rmse\", \n",
    "           labelCol=\"rating\", \n",
    "           predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number models to be tested:  60\n"
     ]
    }
   ],
   "source": [
    "# create grid params model\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [5, 10, 12, 15, 20]) \\\n",
    "            .addGrid(als.regParam, [.1, .12, .14, .16]) \\\n",
    "            .addGrid(als.maxIter, [4, 6, 8]) \\\n",
    "            .build()\n",
    "\n",
    "print (\"Number models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(\n",
    "    estimator=als, \n",
    "    estimatorParamMaps=param_grid, \n",
    "    evaluator=evaluator,\n",
    "    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)\n",
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Best Model**\n",
      "  Rank: 20\n",
      "  MaxIter: 8\n",
      "  RegParam: 0.14\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "# Print \"Rank\"\n",
    "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8754351890823613\n"
     ]
    }
   ],
   "source": [
    "# View the predictions\n",
    "test_predictions = best_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "# test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=20\n",
    "maxIter=8\n",
    "regParam=0.14\n",
    "\n",
    "# Create ALS model again\n",
    "final_als = ALS(\n",
    "        rank=rank,\n",
    "        maxIter=maxIter,\n",
    "        regParam=regParam,\n",
    "        userCol=\"userId\", \n",
    "        itemCol=\"movieId\",\n",
    "        ratingCol=\"rating\", \n",
    "        nonnegative = True, \n",
    "        implicitPrefs = False,\n",
    "        coldStartStrategy=\"drop\",\n",
    "        seed=432\n",
    ")\n",
    "\n",
    "final_model = final_als.fit(train)\n",
    "\n",
    "# View the predictions\n",
    "test_predictions = final_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "\n",
    "# test_predictions.toPandas().to_csv('predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model = ALSModel.load(\"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recommendation usersubset\n",
    "# users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "users = spark.createDataFrame([148], IntegerType()).toDF('userId')\n",
    "userSubsetRecs = final_model.recommendForUserSubset(users, 2)\n",
    "\n",
    "nrecommendations = userSubsetRecs\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n",
    "\n",
    "# users.show()\n",
    "# for ranking, (movieId, rating) in enumerate(userSubsetRecs[0]['recommendations']):\n",
    "#     title = movies.where(movies.movieId == movieId).take(1)[0]['title']\n",
    "#     print(f'Recommendation {ranking+1}: {title} | predicted score: {rating}'.format())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n Recommendations for all users\n",
    "nrecommendations = final_model.recommendForAllUsers(10)\n",
    "nrecommendations = nrecommendations\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n",
    "\n",
    "nrecommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check recommendation  \n",
    "nrecommendations.join(movies, on='movieId').filter('userId = 100').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+--------------------+--------------------+\n",
      "|movieId|userId|rating|               title|              genres|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "|   1101|   100|   5.0|      Top Gun (1986)|      Action|Romance|\n",
      "|   1958|   100|   5.0|Terms of Endearme...|        Comedy|Drama|\n",
      "|   2423|   100|   5.0|Christmas Vacatio...|              Comedy|\n",
      "|   4041|   100|   5.0|Officer and a Gen...|       Drama|Romance|\n",
      "|   5620|   100|   5.0|Sweet Home Alabam...|      Comedy|Romance|\n",
      "|    368|   100|   4.5|     Maverick (1994)|Adventure|Comedy|...|\n",
      "|    934|   100|   4.5|Father of the Bri...|              Comedy|\n",
      "|    539|   100|   4.5|Sleepless in Seat...|Comedy|Drama|Romance|\n",
      "|     16|   100|   4.5|       Casino (1995)|         Crime|Drama|\n",
      "|    553|   100|   4.5|    Tombstone (1993)|Action|Drama|Western|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check movies rated \n",
    "ratings.join(movies, on='movieId').filter('userId = 100').sort('rating', ascending=False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "final_model.save(\"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732556287231764\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|      6|   4.0| 4.5949717|\n",
      "|     1|     47|   5.0| 4.5823603|\n",
      "|     1|    163|   5.0|  4.010098|\n",
      "|     1|    216|   5.0|  4.128422|\n",
      "|     1|    316|   3.0|  3.763847|\n",
      "|     1|    367|   4.0| 3.8843725|\n",
      "|     1|    552|   4.0| 3.7210417|\n",
      "|     1|    553|   5.0| 4.6246066|\n",
      "|     1|    590|   4.0| 4.3124084|\n",
      "|     1|    593|   4.0| 4.7583666|\n",
      "|     1|    648|   3.0|  4.013749|\n",
      "|     1|   1009|   3.0| 3.2530835|\n",
      "|     1|   1023|   5.0|  4.094334|\n",
      "|     1|   1090|   4.0|  4.602919|\n",
      "|     1|   1092|   5.0| 3.6413941|\n",
      "|     1|   1136|   5.0| 4.8654294|\n",
      "|     1|   1196|   5.0| 4.9686337|\n",
      "|     1|   1206|   5.0|  4.465945|\n",
      "|     1|   1256|   5.0|  4.551629|\n",
      "|     1|   1265|   4.0| 4.7060924|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_model = ALSModel.load(\"final_model\")\n",
    "\n",
    "test_predictions = load_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "\n",
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample new user\n",
    "def new_user_recomendatios(user_id, ratings, movies, num_ratings, num_recs):\n",
    "    samples = ratings.sample(False, .001, seed=100).collect()\n",
    "    # get list movieId\n",
    "    sample_list = [i[1] for i in samples]\n",
    "    new_ratings = []\n",
    "    # get nre user rating\n",
    "    for i in range(len(sample_list)):\n",
    "        # print movie title by movie id in sample list\n",
    "        print(movies.where(movies.movieId == sample_list[i]).take(1)[0]['title'])\n",
    "        rating = input('rate this movie 1-5, press n if you have not seen:\\n')\n",
    "        \n",
    "        if rating == 'n':\n",
    "            continue\n",
    "        else:\n",
    "            new_ratings.append((user_id, sample_list[i], float(rating)))\n",
    "            num_ratings -= 1\n",
    "            if num_ratings == 0 : \n",
    "                break\n",
    "\n",
    "    # new_ratings into dataframe base on ratings column\n",
    "    new_user_ratings = spark.createDataFrame(new_ratings, ratings.columns)\n",
    "\n",
    "    combined_movie_ratings = ratings.union(new_user_ratings)\n",
    "\n",
    "    # Create ALS model again\n",
    "    als = ALS(\n",
    "            rank=10,\n",
    "            maxIter=50,\n",
    "            regParam=0.15,\n",
    "            userCol=\"userId\", \n",
    "            itemCol=\"movieId\",\n",
    "            ratingCol=\"rating\", \n",
    "            nonnegative = True, \n",
    "            implicitPrefs = False,\n",
    "            coldStartStrategy=\"drop\"\n",
    "    )\n",
    "\n",
    "    model = als.fit(combined_movie_ratings)\n",
    "\n",
    "    recomendations = model.recommendForAllUsers(num_recs)\n",
    "\n",
    "    recomendation_for_user = recomendations.where(recomendations.userId == user_id).take(1)\n",
    "    # enumerate for  ranking\n",
    "    for ranking, (movieId, rating) in enumerate(recomendation_for_user[0]['recommendations']):\n",
    "        title = movies.where(movies.movieId == movieId).take(1)[0]['title']\n",
    "        print(f'Recommendation {ranking+1}: {title} | predicted score: {rating}'.format())\n",
    "\n",
    "new_user_recomendatios(2138, ratings=ratings, movies=movies, num_ratings=5, num_recs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ratings = ratings\n",
    "# new_ratings = []\n",
    "# new_ratings.append((8382,101,5.0))\n",
    "# # new ratings into dataframe base on ratings column\n",
    "# new_user_ratings = spark.createDataFrame(new_ratings, test_ratings.columns)\n",
    "\n",
    "# combined_movie_ratings = test_ratings.union(new_user_ratings)\n",
    "\n",
    "\n",
    "# # Create ALS model again\n",
    "# als = ALS(\n",
    "#         rank=10,\n",
    "#         maxIter=50,\n",
    "#         regParam=0.15,\n",
    "#         userCol=\"userId\", \n",
    "#         itemCol=\"movieId\",\n",
    "#         ratingCol=\"rating\", \n",
    "#         nonnegative = True, \n",
    "#         implicitPrefs = False,\n",
    "#         coldStartStrategy=\"drop\"\n",
    "# )\n",
    "\n",
    "# model = als.fit(combined_movie_ratings)\n",
    "\n",
    "# recomendations = model.recommendForAllUsers(10)\n",
    "# # nrecomendations = final_model.recommendForAllUsers(1)\n",
    "# users = spark.createDataFrame([148, 1], IntegerType()).toDF('userId')\n",
    "# nrecomendations = final_model.recommendForUserSubset(users, 2)\n",
    "\n",
    "\n",
    "# recs_for_user = nrecomendations.where(nrecomendations.userId == 100).take(1)\n",
    "# recs_for_user[0]['recommendations']\n",
    "\n",
    "# for ranking, (movieId, rating) in enumerate(recs_for_user[0]['recommendations']):\n",
    "#     movie_string = movies.where(movies.movieId == movieId).take(1)[0]['title']\n",
    "#     print('Recommendation {}: {} | predicted score: {}'.format(ranking+1, movie_string, rating))\n",
    "\n",
    "# recs_users = {}\n",
    "\n",
    "# for userId, recs in nrecomendations.collect(): \n",
    "#      recs_users[userId] = [recs]\n",
    "\n",
    "# user_recs = recs_users[148]\n",
    "\n",
    "\n",
    "# moveie = movies_links.join(user_recs, ['movieId'], 'left').dropna(how=\"any\")\\\n",
    "#     .select(\"movieId\",\"title\",\"year\",\"poster\", \"rating\", \"summary\", \"time\", \"genres\" )\n",
    "\n",
    "# print(recs_users)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7da3933e2ab7c21c191def8ae8a7858f78a4b38996aa1ae088d08b10bac0b55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
