{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import col, explode, udf, lit\n",
    "from pyspark.sql.types import IntegerType, FloatType, ArrayType, StringType\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Recommendation\") \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\",\"mongodb://localhost:27017/imdb.movies\")\\\n",
    "    .config(\"spark.mongodb.read.connection.uri\",\"mongodb://localhost:27017/imdb.movies\")\\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector:10.0.5\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.csv(\"data/movies.csv\",header=True)\n",
    "ratings = spark.read.csv(\"data/ratings.csv\",header=True)\n",
    "links = spark.read.csv(\"data/links.csv\",header=True)\n",
    "imdb = spark.read.option(\"multiline\",\"true\").json(\"data.json\")\n",
    "\n",
    "\n",
    "movies_links = movies.join(links, ['movieId'], 'left')\\\n",
    "    .withColumnRenamed('title', 'old_title')\\\n",
    "    .withColumnRenamed('genres', 'old_genres')\\\n",
    "    .drop('tmdbId')\n",
    "\n",
    "movies_imdb = movies_links.join(imdb, ['imdbId'], 'left').dropna(how=\"any\")\\\n",
    "    .select(\"imdbId\",\"movieId\",\"title\",\"year\",\"poster\", \"rating\", \"summary\", \"time\", \"genres\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# insert movies_imdb to collection \n",
    "import json\n",
    "\n",
    "def lower_case(x):\n",
    "    res = []\n",
    "    for x_ in x:\n",
    "        res.append(x_.lower())\n",
    "    return res\n",
    "\n",
    "to_lower_case = udf(lower_case, ArrayType(StringType()))\n",
    "\n",
    "movies_imdb_convert = movies_imdb.withColumn(\"imdbId\",movies_imdb.imdbId.cast(IntegerType())) \\\n",
    "    .withColumn('movieId', movies_imdb.movieId.cast(IntegerType())) \\\n",
    "    .withColumn('rating', movies_imdb.rating.cast(FloatType()))\\\n",
    "    .withColumn(\"genres\", to_lower_case(col(\"genres\")))\\\n",
    "    .select(\"imdbId\",\"movieId\",\"title\",\"year\",\"poster\", \"rating\", \"summary\", \"time\", \"genres\" )\n",
    "\n",
    "\n",
    "# convert_to_lower = udf(lower_case, ArrayType(StringType()))\n",
    "\n",
    "# movies_imdb_convert = movies_imdb\n",
    "\n",
    "movies_imdb_convert.write.format(\"mongodb\").mode(\"overwrite\").save()\n",
    "# genres = movies_imdb.select(\"genres\")\n",
    "# convert = genres.withColumn(\"new_genres\", retrieve_array(col(\"genres\")))\n",
    "\n",
    "# movies_imdb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2779"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading csvs\n",
    "linksdf = pd.read_csv('data/links.csv', index_col='movieId',\n",
    "                        dtype={'imdbId': str, 'tmdbId': str})\n",
    "moviesdf = pd.read_csv('data/movies.csv', index_col='movieId')\n",
    "df = pd.concat([moviesdf, linksdf], axis=1)\n",
    "df = df.iloc[::-1]\n",
    "\n",
    "# gettings imdb ids\n",
    "movieIds = {}\n",
    "movieGenres = df['genres'].tolist()\n",
    "\n",
    "for i in range(len(movieGenres)):\n",
    "    genre = movieGenres[i].split('|')[0]\n",
    "    if genre in movieIds:\n",
    "        # if len(movieIds[genre]) < 15:\n",
    "        movieIds[genre].append(df.iloc[i]['imdbId'])\n",
    "    else:\n",
    "        movieIds[genre] = [df.iloc[i]['imdbId']]\n",
    "\n",
    "del movieIds['(no genres listed)']\n",
    "len(movieIds['Comedy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Join both the data frames to add movie data into ratings\n",
    "# movie_ratings = ratings.join(movies, ['movieId'], 'left')\n",
    "# movie_ratings.printSchema()\n",
    "\n",
    "ratings = ratings.withColumn(\"userId\",ratings.userId.cast(IntegerType())) \\\n",
    "    .withColumn('movieId', ratings.movieId.cast(IntegerType())) \\\n",
    "    .withColumn('rating', ratings.rating.cast(FloatType()))\\\n",
    "    .drop('timestamp')\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  98.30% sparse.\n"
     ]
    }
   ],
   "source": [
    "def get_sparsity(ratings):\n",
    "    # Count the total number of ratings in the dataset\n",
    "    count_nonzero = ratings.select(\"rating\").count()\n",
    "\n",
    "    # Count the number of distinct userIds and distinct movieIds\n",
    "    denominator = ratings.select(\"userId\").distinct().count() * ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "    \n",
    "\n",
    "    # Divide the numerator by the denominator\n",
    "    sparsity = (1.0 - (count_nonzero *1.0)/denominator)*100\n",
    "    print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% sparse.\")\n",
    "    \n",
    "get_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   414| 2698|\n",
      "|   599| 2478|\n",
      "|   474| 2108|\n",
      "|   448| 1864|\n",
      "|   274| 1346|\n",
      "|   610| 1302|\n",
      "|    68| 1260|\n",
      "|   380| 1218|\n",
      "|   606| 1115|\n",
      "|   288| 1055|\n",
      "|   249| 1046|\n",
      "|   387| 1027|\n",
      "|   182|  977|\n",
      "|   307|  975|\n",
      "|   603|  943|\n",
      "|   298|  939|\n",
      "|   177|  904|\n",
      "|   318|  879|\n",
      "|   232|  862|\n",
      "|   480|  836|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data by userId, count ratings\n",
    "userId_ratings = ratings.groupBy(\"userId\").count().orderBy('count', ascending=False)\n",
    "userId_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|    356|  329|\n",
      "|    318|  317|\n",
      "|    296|  307|\n",
      "|    593|  279|\n",
      "|   2571|  278|\n",
      "|    260|  251|\n",
      "|    480|  238|\n",
      "|    110|  237|\n",
      "|    589|  224|\n",
      "|    527|  220|\n",
      "|   2959|  218|\n",
      "|      1|  215|\n",
      "|   1196|  211|\n",
      "|   2858|  204|\n",
      "|     50|  204|\n",
      "|     47|  203|\n",
      "|    780|  202|\n",
      "|    150|  201|\n",
      "|   1198|  200|\n",
      "|   4993|  198|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data by userId, count ratings\n",
    "movieId_ratings = ratings.groupBy(\"movieId\").count().orderBy('count', ascending=False)\n",
    "movieId_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required functions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([.8, .2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN \n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(\n",
    "         userCol=\"userId\", \n",
    "         itemCol=\"movieId\",\n",
    "         ratingCol=\"rating\", \n",
    "         nonnegative = True, \n",
    "         implicitPrefs = False,\n",
    "         coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "type(als)\n",
    "\n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "           metricName=\"rmse\", \n",
    "           labelCol=\"rating\", \n",
    "           predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  16\n"
     ]
    }
   ],
   "source": [
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [5, 10, 20, 30]) \\\n",
    "            .addGrid(als.regParam, [0.001, .01, .05, .1]) \\\n",
    "            .build()\n",
    "\n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/01 22:30:27 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/01/01 22:30:27 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/01/01 22:30:27 WARN InstanceBuilder$JavaBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 853\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    854\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Fit cross validator to the 'train' dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39;49mfit(train)\n\u001b[1;32m      3\u001b[0m \u001b[39m#Extract best model from the cv model above\u001b[39;00m\n\u001b[1;32m      4\u001b[0m best_model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mbestModel\n",
      "File \u001b[0;32m~/Desktop/flask-als/venv/lib/python3.9/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(dataset)\n\u001b[1;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/flask-als/venv/lib/python3.9/site-packages/pyspark/ml/tuning.py:847\u001b[0m, in \u001b[0;36mCrossValidator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    841\u001b[0m train \u001b[39m=\u001b[39m datasets[i][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcache()\n\u001b[1;32m    843\u001b[0m tasks \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\n\u001b[1;32m    844\u001b[0m     inheritable_thread_target,\n\u001b[1;32m    845\u001b[0m     _parallelFitTasks(est, train, eva, validation, epm, collectSubModelsParam),\n\u001b[1;32m    846\u001b[0m )\n\u001b[0;32m--> 847\u001b[0m \u001b[39mfor\u001b[39;00m j, metric, subModel \u001b[39min\u001b[39;00m pool\u001b[39m.\u001b[39mimap_unordered(\u001b[39mlambda\u001b[39;00m f: f(), tasks):\n\u001b[1;32m    848\u001b[0m     metrics_all[i][j] \u001b[39m=\u001b[39m metric\n\u001b[1;32m    849\u001b[0m     \u001b[39mif\u001b[39;00m collectSubModelsParam:\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py:858\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 858\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    859\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    860\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)\n",
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Best Model**\n",
      "  Rank: 100\n",
      "  MaxIter: 10\n",
      "  RegParam: 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"**Best Model**\")\n",
    "# Print \"Rank\"\n",
    "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8786363445184214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# View the predictions\n",
    "test_predictions = best_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "# test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732556287231745\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   148|   5618|   3.0| 3.7377372|\n",
      "|   148|  54001|   4.0| 3.7215872|\n",
      "|   148|  81834|   4.0| 3.7021964|\n",
      "|   148|  81847|   4.5|  3.556174|\n",
      "|   148|  89745|   4.0| 3.4501503|\n",
      "|   148|  98491|   5.0| 3.6914907|\n",
      "|   148|  99149|   3.0| 3.3535335|\n",
      "|   148| 122886|   3.5| 3.0934284|\n",
      "|   463|    110|   4.5|  4.021294|\n",
      "|   463|    520|   4.0| 3.2583194|\n",
      "|   463|   1320|   4.0| 3.2176085|\n",
      "|   463|   2019|   4.0| 3.9286242|\n",
      "|   463|   2167|   3.0| 3.6318412|\n",
      "|   463|   3448|   3.0| 3.6441896|\n",
      "|   463|   3753|   4.0| 3.5524113|\n",
      "|   471|   2571|   3.5|  3.708087|\n",
      "|   471|   4886|   4.0| 3.4968083|\n",
      "|   471|   7147|   4.0| 3.4445422|\n",
      "|   471|   8874|   3.5| 3.7928448|\n",
      "|   471|  68157|   4.0| 3.8135772|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank=10\n",
    "maxIter=10\n",
    "regParam=0.15\n",
    "\n",
    "# Create ALS model again\n",
    "final_als = ALS(\n",
    "        rank=rank,\n",
    "        maxIter=maxIter,\n",
    "        regParam=regParam,\n",
    "        userCol=\"userId\", \n",
    "        itemCol=\"movieId\",\n",
    "        ratingCol=\"rating\", \n",
    "        nonnegative = True, \n",
    "        implicitPrefs = False,\n",
    "        coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "final_model = final_als.fit(train)\n",
    "\n",
    "# View the predictions\n",
    "test_predictions = final_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = ALSModel.load(\"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93008, 25906]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "users = spark.createDataFrame([148], IntegerType()).toDF('userId')\n",
    "userSubsetRecs = final_model.recommendForUserSubset(users, 2)\n",
    "nrecommendations = userSubsetRecs\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n",
    "\n",
    "nrecommendations = userSubsetRecs\\\n",
    "            .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "            .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n",
    "\n",
    "# # users.show()\n",
    "# for ranking, (movieId, rating) in enumerate(userSubsetRecs[0]['recommendations']):\n",
    "#     title = movies.where(movies.movieId == movieId).take(1)[0]['title']\n",
    "#     print(\n",
    "#         f'Recommendation {ranking+1}: {title} | predicted score: {rating}'.format())\n",
    "df = nrecommendations.toPandas()\n",
    "\n",
    "df[\"movieId\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+\n",
      "|userId|movieId|   rating|\n",
      "+------+-------+---------+\n",
      "|     1|   5490|5.7319317|\n",
      "|     1|   5915|5.7319317|\n",
      "|     1| 171495| 5.560452|\n",
      "|     1|   6818|5.5255785|\n",
      "|     1|  33649| 5.514558|\n",
      "|     1|  27523| 5.458926|\n",
      "|     1|   4429|5.4469056|\n",
      "|     1| 102217| 5.435365|\n",
      "|     1|  33779| 5.435365|\n",
      "|     1|  69524| 5.430213|\n",
      "+------+-------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Generate n Recommendations for all users\n",
    "nrecommendations = final_model.recommendForAllUsers(10)\n",
    "nrecommendations = nrecommendations\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n",
    "\n",
    "nrecommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------------------+--------------------+\n",
      "|movieId|userId|   rating|               title|              genres|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "|  42730|   100|5.1454678|   Glory Road (2006)|               Drama|\n",
      "|  67618|   100|5.1370006|Strictly Sexual (...|Comedy|Drama|Romance|\n",
      "| 112804|   100| 5.040798|    I Origins (2014)|        Drama|Sci-Fi|\n",
      "|   3086|   100|5.0038996|Babes in Toyland ...|Children|Comedy|F...|\n",
      "|  93008|   100| 4.972296|Very Potter Seque...|      Comedy|Musical|\n",
      "|  77846|   100| 4.972296| 12 Angry Men (1997)|         Crime|Drama|\n",
      "|  25906|   100| 4.972296|Mr. Skeffington (...|       Drama|Romance|\n",
      "| 183897|   100| 4.956506| Isle of Dogs (2018)|    Animation|Comedy|\n",
      "|   4495|   100|4.9558105|Crossing Delancey...|      Comedy|Romance|\n",
      "|   6201|   100|4.9558105|    Lady Jane (1986)|       Drama|Romance|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrecommendations.join(movies, on='movieId').filter('userId = 100').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+--------------------+--------------------+\n",
      "|movieId|userId|rating|               title|              genres|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "|   1101|   100|   5.0|      Top Gun (1986)|      Action|Romance|\n",
      "|   1958|   100|   5.0|Terms of Endearme...|        Comedy|Drama|\n",
      "|   2423|   100|   5.0|Christmas Vacatio...|              Comedy|\n",
      "|   4041|   100|   5.0|Officer and a Gen...|       Drama|Romance|\n",
      "|   5620|   100|   5.0|Sweet Home Alabam...|      Comedy|Romance|\n",
      "|    368|   100|   4.5|     Maverick (1994)|Adventure|Comedy|...|\n",
      "|    934|   100|   4.5|Father of the Bri...|              Comedy|\n",
      "|    539|   100|   4.5|Sleepless in Seat...|Comedy|Drama|Romance|\n",
      "|     16|   100|   4.5|       Casino (1995)|         Crime|Drama|\n",
      "|    553|   100|   4.5|    Tombstone (1993)|Action|Drama|Western|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.join(movies, on='movieId').filter('userId = 100').sort('rating', ascending=False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19475:===============================================>    (91 + 8) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+\n",
      "|movieId|userId|   rating|\n",
      "+-------+------+---------+\n",
      "|     26|    53| 4.585873|\n",
      "|     26|    43|4.4174333|\n",
      "|     26|   171|4.3215876|\n",
      "|     26|   389| 4.232469|\n",
      "|     26|   452| 4.170912|\n",
      "|     26|   122| 4.124021|\n",
      "|     26|   250| 4.111661|\n",
      "|     26|   269|4.0804043|\n",
      "|     26|    40| 4.076036|\n",
      "|     26|    93|4.0574923|\n",
      "+-------+------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "irecommendations = best_model.recommendForAllItems(10)\n",
    "irecommendations = irecommendations\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select(col('movieId'), col(\"rec_exp.userId\"), col(\"rec_exp.rating\"))\n",
    "\n",
    "irecommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save(\"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732556287231764\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|      6|   4.0| 4.5949717|\n",
      "|     1|     47|   5.0| 4.5823603|\n",
      "|     1|    163|   5.0|  4.010098|\n",
      "|     1|    216|   5.0|  4.128422|\n",
      "|     1|    316|   3.0|  3.763847|\n",
      "|     1|    367|   4.0| 3.8843725|\n",
      "|     1|    552|   4.0| 3.7210417|\n",
      "|     1|    553|   5.0| 4.6246066|\n",
      "|     1|    590|   4.0| 4.3124084|\n",
      "|     1|    593|   4.0| 4.7583666|\n",
      "|     1|    648|   3.0|  4.013749|\n",
      "|     1|   1009|   3.0| 3.2530835|\n",
      "|     1|   1023|   5.0|  4.094334|\n",
      "|     1|   1090|   4.0|  4.602919|\n",
      "|     1|   1092|   5.0| 3.6413941|\n",
      "|     1|   1136|   5.0| 4.8654294|\n",
      "|     1|   1196|   5.0| 4.9686337|\n",
      "|     1|   1206|   5.0|  4.465945|\n",
      "|     1|   1256|   5.0|  4.551629|\n",
      "|     1|   1265|   4.0| 4.7060924|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_model = ALSModel.load(\"final_model\")\n",
    "\n",
    "test_predictions = load_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "\n",
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_user_recomendatios(user_id, ratings, movies, num_ratings, num_recs):\n",
    "    samples = ratings.sample(False, .001, seed=100).collect()\n",
    "    # get list movieId\n",
    "    sample_list = [i[1] for i in samples]\n",
    "    new_ratings = []\n",
    "    # get nre user rating\n",
    "    for i in range(len(sample_list)):\n",
    "        # print movie title by movie id in sample list\n",
    "        print(movies.where(movies.movieId == sample_list[i]).take(1)[0]['title'])\n",
    "        rating = input('rate this movie 1-5, press n if you have not seen:\\n')\n",
    "        \n",
    "        if rating == 'n':\n",
    "            continue\n",
    "        else:\n",
    "            new_ratings.append((user_id, sample_list[i], float(rating)))\n",
    "            num_ratings -= 1\n",
    "            if num_ratings == 0 : \n",
    "                break\n",
    "\n",
    "    # new_ratings into dataframe base on ratings column\n",
    "    new_user_ratings = spark.createDataFrame(new_ratings, ratings.columns)\n",
    "\n",
    "    combined_movie_ratings = ratings.union(new_user_ratings)\n",
    "\n",
    "    # Create ALS model again\n",
    "    als = ALS(\n",
    "            rank=10,\n",
    "            maxIter=50,\n",
    "            regParam=0.15,\n",
    "            userCol=\"userId\", \n",
    "            itemCol=\"movieId\",\n",
    "            ratingCol=\"rating\", \n",
    "            nonnegative = True, \n",
    "            implicitPrefs = False,\n",
    "            coldStartStrategy=\"drop\"\n",
    "    )\n",
    "\n",
    "    model = als.fit(combined_movie_ratings)\n",
    "\n",
    "    recomendations = model.recommendForAllUsers(num_recs)\n",
    "\n",
    "    recomendation_for_user = recomendations.where(recomendations.userId == user_id).take(1)\n",
    "    # enumerate for  ranking\n",
    "    for ranking, (movieId, rating) in enumerate(recomendation_for_user[0]['recommendations']):\n",
    "        title = movies.where(movies.movieId == movieId).take(1)[0]['title']\n",
    "        print(f'Recommendation {ranking+1}: {title} | predicted score: {rating}'.format())\n",
    "\n",
    "new_user_recomendatios(2138, ratings=ratings, movies=movies, num_ratings=5, num_recs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ratings = ratings\n",
    "# new_ratings = []\n",
    "# new_ratings.append((8382,101,5.0))\n",
    "# # new ratings into dataframe base on ratings column\n",
    "# new_user_ratings = spark.createDataFrame(new_ratings, test_ratings.columns)\n",
    "\n",
    "# combined_movie_ratings = test_ratings.union(new_user_ratings)\n",
    "\n",
    "\n",
    "# # Create ALS model again\n",
    "# als = ALS(\n",
    "#         rank=10,\n",
    "#         maxIter=50,\n",
    "#         regParam=0.15,\n",
    "#         userCol=\"userId\", \n",
    "#         itemCol=\"movieId\",\n",
    "#         ratingCol=\"rating\", \n",
    "#         nonnegative = True, \n",
    "#         implicitPrefs = False,\n",
    "#         coldStartStrategy=\"drop\"\n",
    "# )\n",
    "\n",
    "# model = als.fit(combined_movie_ratings)\n",
    "\n",
    "# # recomendations = model.recommendForAllUsers(10)\n",
    "# nrecomendations = best_model.recommendForAllUsers(10)\n",
    "\n",
    "# recs_for_user = nrecomendations.where(nrecomendations.userId == 100).take(1)\n",
    "# recs_for_user[0]['recommendations']\n",
    "\n",
    "# for ranking, (movieId, rating) in enumerate(recs_for_user[0]['recommendations']):\n",
    "#     movie_string = movies.where(movies.movieId == movieId).take(1)[0]['title']\n",
    "#     print('Recommendation {}: {} | predicted score: {}'.format(ranking+1, movie_string, rating))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7da3933e2ab7c21c191def8ae8a7858f78a4b38996aa1ae088d08b10bac0b55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
